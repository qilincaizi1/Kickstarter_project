---
title: "Modeling_Other"
author: "Tingrui Huang"
date: "December 3, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Package
```{r }
library(tidyverse)
library(Matrix)
library(lme4)
library(coefplot)
library(kableExtra)
library(stargazer)
library(carData)
library(car)
library(alr3)
library(zoo)
library(lmtest)
library(sjPlot)
library(sjlabelled)
library(sjmisc)
library(magrittr)
library(MASS)
library(arm)
library(lattice)
library(caret)
library(gplots)
library(ROCR)
library(e1071)
library(randomForest)
library(randomForestExplainer)
```

### Import dataset and Preparation
```{r }
kickstarter <- read.csv("C:/Users/Qilincaizi/Desktop/BU_MSSP/Fall_2018/MA678_Appl_Stat_Model/Midterm_Project/dataset/kickstarter.csv")
ks <- kickstarter
# Reformat Deadline and Launched to Data
ks$deadline <- as.Date(ks$deadline, "%m/%d/%Y")
ks$launched <- as.Date(ks$launched, "%m/%d/%Y")
# Extract launched year and month
ks <- ks %>% mutate(launched_year=format(as.Date(launched, format="%m/%d/%Y"),"%Y"))
ks <- ks %>% mutate(launched_month=format(as.Date(launched, format="%m/%d/%Y"),"%m"))
# Found some projects launched in 1970. I believe these projects were canceled. Thus, remove these projects
ks <- ks[-c(2843,48148,75398,94580,247914,273780,319003),]
# Add new column to store duration of the project
ks <- ks %>% mutate(duration=as.integer(deadline-launched))
# Add new column to store the ratio of goal and pledged (use usd_goal_real and usd_pledged_real)
ks <- ks %>% mutate(ratio=round(usd_pledged_real/usd_goal_real, digits = 4))
# Found 4 projects have ratio smaller than 1 but classified as "successful"
ks$state[ks$ratio < 0.99999 & ks$state == "successful"] = "failed"
# Do the same for projects have ratio greater than 1 but classified as "failed"
ks$state[ks$ratio >= 1 & ks$state == "failed"] = "successful"
ks <- ks %>% select(state,backers,duration,usd_goal_real,main_category,category,country,launched_year) %>% na.omit()
# Success and Fail
kssf <- ks %>% filter(state==c("successful","failed")) %>% droplevels()
kssf$launched_year <- as.numeric(kssf$launched_year)
kssf %<>% mutate(log_usd_goal_real=log(usd_goal_real))
# kssf %<>% mutate(state=ifelse(state=="successful",1,0))  # Success=1, Failed=0
```
    
## Data Partition
```{r }
set.seed(999)
dp_index_sf <- rbinom(nrow(kssf),1,prob = 0.7)
df_train_sf <- as.data.frame(kssf[dp_index_sf==1,])
df_test_sf <- as.data.frame(kssf[dp_index_sf==0,])
```

## Variable selection
Outcome variables - state
Input variables - 
    Fixed effects: (backers), duration, usd_goal_real
    Random effects: main_category:category, country, launched_year
    
## Random Forest
Random Forests are similar to a famous Ensemble technique called Bagging but have a different tweak in it. In Random Forests the idea is to decorrelate the several trees which are generated by the different bootstrapped samples from training Data. And then we simply reduce the Variance in the Trees by averaging them.Averaging the Trees helps us to reduce the variance and also improve the Performance of Decision Trees on Test Set and eventually avoid Overfitting.
```{r }
# Random Forest
rf1 <- randomForest(state~duration+usd_goal_real+main_category+country+as.numeric(launched_year),
                    data = df_train_sf, ntree=100, importance=TRUE)
# Increase number of trees
rf2 <- randomForest(state~duration+usd_goal_real+main_category+country+as.numeric(launched_year),
                    data = df_train_sf, ntree=500, importance=TRUE)
# Find the optimal mtry value - Select mtry value with minimum out of bag(OOB) error
mtry <- tuneRF(df_train_sf[-c(1,6)],df_train_sf$state, ntreeTry=500,
               stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
print(mtry)
print(best.m)
# Model with optimal mtry
rf3 <- randomForest(state~duration+usd_goal_real+main_category+country+as.numeric(launched_year),
                    data = df_train_sf, ntree=500, mtry=best.m, importance=TRUE)
# Importance of Variables
importance(rf3)
varImpPlot(rf3, pch = 20, main = "Importance of Variables")
# Prediction
rf_pred <- predict(rf3, newdata = df_test_sf) #,type = "prob"
# Confusion matrix
confusionMatrix(rf_pred, df_test_sf$state)
# ROC Curve
perf <- prediction(rf_pred[,2], df_test_sf$state) 
pred3 <- performance(perf, "tpr","fpr")
plot(pred3,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
# Plot
plot(rf3, main = "Error rate of random forest")

# Add backers
rf4 <- randomForest(state~duration+usd_goal_real+main_category+country+launched_year+backers,
                    data = df_train_sf, ntree=500, mtry=best.m, importance=TRUE)
# Importance of Variables
importance(rf4)
varImpPlot(rf4, pch = 20, main = "Importance of Variables")
# Prediction
rf_pred2 <- predict(rf4, newdata = df_test_sf) #,type = "prob"
# Confusion matrix
confusionMatrix(rf_pred2, df_test_sf$state)
# ROC Curve
perf2 <- prediction(rf_pred2[,2], df_test_sf$state)
pred4 <- performance(perf2, "tpr","fpr")
plot(pred4,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
# Plot
plot(rf4, main = "Error rate of random forest")
# Prediction with mean backers
df_test_sf_m <- df_test_sf %>% group_by(category) %>% mutate(backers=mean(backers))
rf_pred3 <- predict(rf4, newdata = df_test_sf_m,type = "prob") #,type = "prob"
confusionMatrix(rf_pred3, df_test_sf$state)
perf3 <- prediction(rf_pred3[,2], df_test_sf$state)
pred5 <- performance(perf3, "tpr","fpr")
plot(pred5,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
# random forest explainer
plot_multi_way_importance(rf3, size_measure = "no_of_nodes")
plot_predict_interaction(rf3,df_test_sf,"backers","launched_year")
plot_predict_interaction(rf3,df_test_sf,"duration","log_usd_goal_real")
```

